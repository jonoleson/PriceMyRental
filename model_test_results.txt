**Benchmark RF Regressor**
Method:
-Get median 1 bedroom values in each neighborhood, add this as a feature
-User Random Forest Regressor to predict price based on existing numerical features

Results:
R^2: 0.730
RMSE: 973.441

**NMF + RF Regressor**
Method:
-On top of benchmark method, add latent features weights derived from the description text 
-Use Random Forest Regressor to predict price based on these existing numerical features as well as the latent feature weights

Results:
R^2: 0.807
RMSE: 805.004

**Nearest Neighbors**
Method: 
-Used a KD-Tree to find the nearest neighbors to the each listing, then take the median of the nearest k listings
-Ran the KD-Tree based on lat, long, beds, and baths, which risks throwing out some relevant listings when splitting on the medians of the bed and bath fields

Results:
RMSE: 934.988 with k=20, 883.820 with k=10, 858.585 with k=10

**Nearest Neighbors 2.0**
-Ran the KD-Tree based on only lat and long, then manually extracted the closest listings that had the same layout (# of beds and baths) 
-This ensured that fewer relevant listings were lost due to the splitting mechanism of the KD-Tree

Results:
RMSE: 834.207 with k=5, 831.634 with k=10
-Also, got RMSE=719.928 with k=5 when I accidentally wasn't filtering for listings with the same layout. Need to figure out why. 
-Update: This was because most listings in this case populated NaNs for their median_neighbors price, those that remained had neighbor medians very close to their own price.

**Nearest Neighbors + NMF + RF Regressor**
-Used NMF and the KD-Tree to featurize the df with latent features and the median neighbor price for all the listings

Results:
R^2: 0.859
RMSE: 679.786
